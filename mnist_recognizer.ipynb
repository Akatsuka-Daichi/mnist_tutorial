{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "mnist_recognizer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "71628de8-6e56-42fd-ab40-a371e23d0a0a"
      },
      "source": [
        "%matplotlib inline\n",
        " \n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import random\n",
        "from IPython.display import Image\n"
      ],
      "id": "71628de8-6e56-42fd-ab40-a371e23d0a0a",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "698e8dd5-d1c0-46da-b2cc-a8f56f9eedf1"
      },
      "source": [
        "EPOCHS = 1\n",
        "BATCH_SIZE = 100\n",
        "LEARNING_RATE = 0.0005"
      ],
      "id": "698e8dd5-d1c0-46da-b2cc-a8f56f9eedf1",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f63d5107-f49d-4a33-8931-c6f654ab8138"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3) # 28x28x32 -> 26x26x32\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3) # 26x26x64 -> 24x24x64 \n",
        "        self.pool = nn.MaxPool2d(2, 2) # 24x24x64 -> 12x12x64\n",
        "        self.dropout1 = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(12 * 12 * 64, 128)\n",
        "        self.dropout2 = nn.Dropout2d()\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.dropout1(x)\n",
        "        x = x.view(-1, 12 * 12 * 64)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "id": "f63d5107-f49d-4a33-8931-c6f654ab8138",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cd9a3ef-6fe4-4fbc-b810-b0a4f0d27b99"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, ), (0.5, ))])\n",
        "trainset = torchvision.datasets.MNIST(root='./data', \n",
        "                                        train=True,\n",
        "                                        download=True,\n",
        "                                        transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset,\n",
        "                                            batch_size=BATCH_SIZE,\n",
        "                                            shuffle=True,\n",
        "                                            num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', \n",
        "                                        train=False, \n",
        "                                        download=True, \n",
        "                                        transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, \n",
        "                                            batch_size=BATCH_SIZE,\n",
        "                                            shuffle=False, \n",
        "                                            num_workers=2)\n",
        "\n",
        "classes = tuple(np.linspace(0, 9, 10, dtype=np.uint8))"
      ],
      "id": "3cd9a3ef-6fe4-4fbc-b810-b0a4f0d27b99",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "506f95a2-7454-40b3-9487-9a929a0dd7fd"
      },
      "source": [
        "net = Net()\n",
        "device = torch.device(\"cuda\")\n",
        "net = net.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(),\n",
        "                      lr=LEARNING_RATE, momentum=0.99, nesterov=True)"
      ],
      "id": "506f95a2-7454-40b3-9487-9a929a0dd7fd",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c9a3bda-56ee-45d4-afb5-9d859a959fe1",
        "outputId": "232e61c9-9e36-493c-cc19-7538591dc0a1"
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    print(\"+++ epoch {:d} +++\".format(epoch))\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print(\"   iteration{:5d} ---> loss: {:.3f}\"\n",
        "                  .format(i+1, running_loss/100))\n",
        "            running_loss = 0.0\n",
        "    print(\"\")\n",
        "print('Finished Training')"
      ],
      "id": "0c9a3bda-56ee-45d4-afb5-9d859a959fe1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+++ epoch 0 +++\n",
            "   iteration  100 ---> loss: 2.116\n",
            "   iteration  200 ---> loss: 0.928\n",
            "   iteration  300 ---> loss: 0.552\n",
            "   iteration  400 ---> loss: 0.433\n",
            "   iteration  500 ---> loss: 0.373\n",
            "   iteration  600 ---> loss: 0.350\n",
            "\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d13fd12-796e-452e-b1ee-25998a834248",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "2e37ed8d-9c0b-4e37-ad82-f94b04f13f3f"
      },
      "source": [
        "index = random.randint(0, 99)\n",
        "test_iter = iter(testloader)\n",
        "inputs, labels = test_iter.next()\n",
        "inputs = inputs.to(device)\n",
        "outputs = net(inputs)\n",
        "_, predicted = torch.max(outputs.data, 1)\n",
        "plt.imshow(inputs[index].to('cpu').detach().numpy().copy().reshape(28, 28), cmap='gray')\n",
        "print(\"Predicted Label : \", predicted[index].item())\n",
        "print(\"GT Label : \", labels[index].item())\n"
      ],
      "id": "6d13fd12-796e-452e-b1ee-25998a834248",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted Label :  7\n",
            "GT Label :  7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}