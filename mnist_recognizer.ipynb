{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "mnist_recognizer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "71628de8-6e56-42fd-ab40-a371e23d0a0a"
      },
      "source": [
        "%matplotlib inline\n",
        " \n",
        "# ライブラリのインポート\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import random\n",
        "from IPython.display import Image\n"
      ],
      "id": "71628de8-6e56-42fd-ab40-a371e23d0a0a",
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "698e8dd5-d1c0-46da-b2cc-a8f56f9eedf1"
      },
      "source": [
        "# ハイパーパラメータの設定\n",
        "EPOCHS = 5 # エポック数\n",
        "BATCH_SIZE = 100 # バッチサイズ\n",
        "LEARNING_RATE = 0.0005 # 学習率"
      ],
      "id": "698e8dd5-d1c0-46da-b2cc-a8f56f9eedf1",
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cd9a3ef-6fe4-4fbc-b810-b0a4f0d27b99"
      },
      "source": [
        "# データセットの用意\n",
        "# transformはデータセットに対する前処理を表す\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5, ), (0.5, ))])\n",
        "\n",
        "# datasetsは実際のデータセットを表す\n",
        "# ここではmnistを利用、手元にない場合は自動的にダウンロードする\n",
        "# またtransformをここでセットする\n",
        "# 学習データ用とテストデータ用を２つ用意する\n",
        "trainset = torchvision.datasets.MNIST(\n",
        "    root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.MNIST(\n",
        "    root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# DataLoaderはデータセットをバッチサイズごとに利用するためのもの\n",
        "# datasetsをここでセットする\n",
        "# 学習データ用とテストデータ用を２つ用意する\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
      ],
      "id": "3cd9a3ef-6fe4-4fbc-b810-b0a4f0d27b99",
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f63d5107-f49d-4a33-8931-c6f654ab8138"
      },
      "source": [
        "# ネットワークアーキテクチャの構築\n",
        "class Net(nn.Module):\n",
        "    # ここで各層の名前を定義\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 畳み込み層１\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3) # 28x28x32 -> 26x26x32\n",
        "        # 畳み込み層２\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3) # 26x26x64 -> 24x24x64 \n",
        "        # プーリング層\n",
        "        self.pool = nn.MaxPool2d(2, 2) # 24x24x64 -> 12x12x64\n",
        "        # ドロップアウト層１\n",
        "        self.dropout1 = nn.Dropout2d()\n",
        "        # 全結合層１\n",
        "        self.fc1 = nn.Linear(12 * 12 * 64, 128)\n",
        "        # ドロップアウト層２\n",
        "        self.dropout2 = nn.Dropout2d()\n",
        "        # 全結合層２\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    # 層同士の接続を定義\n",
        "    def forward(self, x):\n",
        "        # 入力は28x28(画像サイズが28px*28pxなので)\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x) # 活性化関数を挿入する（ここではReLU関数を使用）\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x) # 活性化関数を挿入する（ここではReLU関数を使用）\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = x.view(-1, 12 * 12 * 64) #　ここで行列をベクトル化（全結合層に入力するため）\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x) # 活性化関数を挿入する（ここではReLU関数を使用）\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        # 出力は10次元（10種類の数字なので）\n",
        "        return x"
      ],
      "id": "f63d5107-f49d-4a33-8931-c6f654ab8138",
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "506f95a2-7454-40b3-9487-9a929a0dd7fd"
      },
      "source": [
        "net = Net() # ネットワークをインスタンス化\n",
        "device = torch.device(\"cuda\") # GPUの設定\n",
        "net = net.to(device) # ネットワークをGPU上に展開\n",
        "criterion = nn.CrossEntropyLoss() # 損失関数の設定（ここではクロスエントロピー誤差を使用）\n",
        "# オプティマイザの設定（どのように重みの値を更新していくかを決める）\n",
        "optimizer = optim.SGD(net.parameters(),\n",
        "                      lr=LEARNING_RATE, momentum=0.99, nesterov=True)"
      ],
      "id": "506f95a2-7454-40b3-9487-9a929a0dd7fd",
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c9a3bda-56ee-45d4-afb5-9d859a959fe1",
        "outputId": "94526ccd-a6c1-41a8-e529-a25ab6d1bbc4"
      },
      "source": [
        "# 実際に学習を進める\n",
        "# ここのforは１回実行されるごとに１エポック分の学習が進む\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"+++ epoch {:d} +++\".format(epoch))\n",
        "\n",
        "    running_loss = 0.0\n",
        "    # ここのforは１回実行されるごとに１バッチ分のデータで学習が進む\n",
        "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad() # 勾配をリセットする（Tensor型は勾配が蓄積してしまうため）\n",
        "        outputs = net(inputs) # 順伝搬を行う\n",
        "        # 順伝搬結果と正解ラベルを元に損失を計算する（正解ラベルとの誤差）\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward() # 誤差逆伝搬を行う\n",
        "        optimizer.step() #　重みを更新\n",
        "\n",
        "        # 表示用コード\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print(\"   iteration{:5d} ---> loss: {:.3f}\"\n",
        "                  .format(i+1, running_loss/100))\n",
        "            running_loss = 0.0\n",
        "    print(\"\")\n",
        "print('Finished Training')"
      ],
      "id": "0c9a3bda-56ee-45d4-afb5-9d859a959fe1",
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+++ epoch 0 +++\n",
            "   iteration  100 ---> loss: 2.191\n",
            "   iteration  200 ---> loss: 1.074\n",
            "   iteration  300 ---> loss: 0.566\n",
            "   iteration  400 ---> loss: 0.452\n",
            "   iteration  500 ---> loss: 0.384\n",
            "   iteration  600 ---> loss: 0.350\n",
            "\n",
            "+++ epoch 1 +++\n",
            "   iteration  200 ---> loss: 0.267\n",
            "   iteration  300 ---> loss: 0.237\n",
            "   iteration  400 ---> loss: 0.218\n",
            "   iteration  500 ---> loss: 0.200\n",
            "   iteration  600 ---> loss: 0.196\n",
            "\n",
            "+++ epoch 2 +++\n",
            "   iteration  100 ---> loss: 0.181\n",
            "   iteration  200 ---> loss: 0.168\n",
            "   iteration  300 ---> loss: 0.157\n",
            "   iteration  400 ---> loss: 0.159\n",
            "   iteration  500 ---> loss: 0.155\n",
            "   iteration  600 ---> loss: 0.145\n",
            "\n",
            "+++ epoch 3 +++\n",
            "   iteration  100 ---> loss: 0.132\n",
            "   iteration  200 ---> loss: 0.139\n",
            "   iteration  300 ---> loss: 0.132\n",
            "   iteration  400 ---> loss: 0.123\n",
            "   iteration  500 ---> loss: 0.125\n",
            "   iteration  600 ---> loss: 0.114\n",
            "\n",
            "+++ epoch 4 +++\n",
            "   iteration  100 ---> loss: 0.114\n",
            "   iteration  200 ---> loss: 0.113\n",
            "   iteration  300 ---> loss: 0.106\n",
            "   iteration  400 ---> loss: 0.103\n",
            "   iteration  500 ---> loss: 0.106\n",
            "   iteration  600 ---> loss: 0.110\n",
            "\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d13fd12-796e-452e-b1ee-25998a834248",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "ebc7d675-0400-4ae7-8c3c-270e31ad3666"
      },
      "source": [
        "# 推論結果例を表示\n",
        "index = random.randint(0, 99) # ランダムに０から９９までの整数を取得\n",
        "test_iter = iter(testloader)\n",
        "inputs, labels = test_iter.next() # テストデータから１バッチ分のデータを取得\n",
        "inputs = inputs.to(device) # テストデータをGPUに展開\n",
        "outputs = net(inputs) # 推論を行う（順伝搬）\n",
        "_, predicted = torch.max(outputs.data, 1) # 推論結果から正解クラス（数字）を出力\n",
        "# 画像を表示\n",
        "plt.imshow(inputs[index].to('cpu').detach().numpy().copy().reshape(28, 28), cmap='gray')\n",
        "print(\"Predicted Label : \", predicted[index].item())\n",
        "print(\"GT Label : \", labels[index].item())\n"
      ],
      "id": "6d13fd12-796e-452e-b1ee-25998a834248",
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted Label :  8\n",
            "GT Label :  9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}